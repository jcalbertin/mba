{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Regressão - MLP TensorFlow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcalbertin/mba/blob/master/Copy_of_Regress%C3%A3o_MLP_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jYysdyb-CaWM"
      },
      "source": [
        "<hr>\n",
        "<h2><center>Disciplina : Redes Neurais Profundas</center></h2>\n",
        "<h2><center>Regressão: Consumo de Combustível - TensorFlow & Keras</center></h2>\n",
        "<center>Prof. Robson Fernandes</center>\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OezgXCpHi4v_"
      },
      "source": [
        "<p>Em um problema de regressão, o objetivo é prever as saídas (<em>outputs</em>) de um valor contínuo, como um preço ou probabilidade. Em contraste de problemas de classificação, onde temos o propósito de escolher uma classe em uma lista de classificações (por exemplo, se uma imagem contém uma maçã ou laranja, assim reconhecendo qual fruta é representada na imagem).</p>\n",
        "<p>Este <em>notebook</em> usa a clássica base de dados <a href=\"https://archive.ics.uci.edu/ml/datasets/auto+mpg\">Auto MPG</a> e constrói um modelo para prever a economia de combustíveis de automóveis do final dos anos 1970, início dos anos 1980. Para isso, forneceremos um modelo com descrição de vários automóveis desse período. Essa descrição inclui atributos como: cilindros, deslocamento, potência do motor, e peso.</p>\n",
        "<p>Este exemplo usa a API <code>tf.keras</code>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dzLKpmZICaWN",
        "colab": {}
      },
      "source": [
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yR0EdgrLCaWR"
      },
      "source": [
        "## Importar a Base de Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DLdCchMdCaWQ"
      },
      "source": [
        "<p>A base de dados está disponível  em <a href=\"https://archive.ics.uci.edu/ml/\">UCI Machine Learning Repository</a>.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7MqDQO0KCaWS",
        "colab": {}
      },
      "source": [
        "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t9FDsUlxCaWW"
      },
      "source": [
        "Utilizando o pandas, impoorte os dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IjnLH5S2CaWx",
        "colab": {}
      },
      "source": [
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
        "                      na_values = \"?\", comment='\\t',\n",
        "                      sep=\" \", skipinitialspace=True)\n",
        "\n",
        "dataset = raw_dataset.copy()\n",
        "dataset.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Brm0b_KACaWX"
      },
      "source": [
        "## Limpe os dados\n",
        "\n",
        "Esta base contém alguns valores não conhecidos (unknown)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zW5k_xz1CaWX",
        "colab": {}
      },
      "source": [
        "dataset.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cIAcvQqMCaWf"
      },
      "source": [
        "Remova as linhas com esses valores não conhecidos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TRFYHB2mCaWb",
        "colab": {}
      },
      "source": [
        "dataset = dataset.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YSlYxFuRCaWk"
      },
      "source": [
        "A coluna \"Origin\" é uma coluna categórica e não numérica. Logo converta para one-hot :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XKnCTHz4CaWg",
        "colab": {}
      },
      "source": [
        "origin = dataset.pop('Origin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvb0WXFk5U-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## variaveis categoricas tem que ser convertidas para números\n",
        "dataset['USA'] = (origin == 1)*1.0\n",
        "dataset['Europe'] = (origin == 2)*1.0\n",
        "dataset['Japan'] = (origin == 3)*1.0\n",
        "dataset.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TMPI88iZpO2T"
      },
      "source": [
        "### Separando dados de treinamento e teste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTxcEP-U5U-o",
        "colab_type": "text"
      },
      "source": [
        "Agora separe os dados em um conjunto de treinamento e outro teste.Iremos utilizar o de conjunto de teste no final da análise do model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2KFnYlcwCaWl",
        "colab": {}
      },
      "source": [
        "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ES6uQoLKCaWr"
      },
      "source": [
        "## Análise Exploratória\n",
        "\n",
        "Veja como está a distribuição de algumas colunas do conjunto de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m4VEw8Ud9Quh",
        "colab": {}
      },
      "source": [
        "sns.pairplot(train_dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\"]], diag_kind=\"kde\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wz7l27Lz9S1P"
      },
      "source": [
        "Veja a estatística geral"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bW5WzIPlCaWv",
        "colab": {}
      },
      "source": [
        "train_stats = train_dataset.describe()\n",
        "train_stats.pop(\"MPG\")\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "59veuiEZCaW4"
      },
      "source": [
        "## Separe features de labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaeFGznO5U-w",
        "colab_type": "text"
      },
      "source": [
        "Separe o valor alvo (labels), das features. Essa label é o valor no qual o modelo é treinado para prever."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5LLq5M05U-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = train_dataset.pop('MPG')\n",
        "test_labels = test_dataset.pop('MPG')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Gxg1XGm0eOBy"
      },
      "source": [
        "### Normalize os dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX9noTNU5U-0",
        "colab_type": "text"
      },
      "source": [
        "Observe novamente o <b>train_stats</b> acima e note quão diferente são os intervalos de uma feature e outra.\n",
        "\n",
        "Uma boa prática é normalizar as features que usam diferentes escalas e intervalos. Apesar do modelo poder convergir sem a normalização, isso torna o treinamento mais difícil, e torna o resultado do modelo dependente da escolha das unidades da entrada.\n",
        "\n",
        "Observação: embora geramos intencionalmente essas estatísticas para os dados de treinamento, essas estatísticas serão usadas também para normalizar o conjunto de teste. Precisamos delinear o conjunto de teste na mesma distribuição que o modelo foi treinado.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9ODch-OFCaW4",
        "colab": {}
      },
      "source": [
        "def norm(x): ##x - cada registro - mormaliza\n",
        "    return (x - train_stats['mean']) / train_stats['std'] # media / desvio padrao\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)\n",
        "\n",
        "print(normed_train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udf2vDu35U-3",
        "colab_type": "text"
      },
      "source": [
        "Esse dado normalizado é o que usaremos para treinar o modelo.\n",
        "\n",
        "Atenção: As estatísticas usadas para normalizar as entradas aqui (média e desvio padrão) precisa ser aplicada em qualquer outro dado que alimenta o modelo, junto com o código one-hot que fizemos anteriormente. Isso inclui o conjunto de teste e os dados que o modelo usará em produção."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qKF6uW-BCaW-"
      },
      "source": [
        "## Contruindo Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zrc8WXKa5U-4",
        "colab_type": "text"
      },
      "source": [
        "Vamos construir o modelo. Aqui usaremos o modelo <b>Sequential</b> com duas camadas densely connected, e a camada de saída que retorna um único valor contínuo. Os passos de construção do modelo são agrupados em uma função, build_model, já que criaremos um segundo modelo mais tarde."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xvwvpA64CaW_",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(64, activation=tf.nn.relu, input_shape=[len(train_dataset.keys())]),\n",
        "        layers.Dense(64, activation=tf.nn.relu),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "    \n",
        "    model.compile(loss='mean_squared_error',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF6Xj37H5U_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hce_fKkC5U_K",
        "colab_type": "text"
      },
      "source": [
        "### Estrutura do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2HJsvEa5U_L",
        "colab_type": "text"
      },
      "source": [
        "Use o método .summary para exibir uma descrição simples do modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYYCM4oS5U_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Suu_u-eD5U_Q",
        "colab_type": "text"
      },
      "source": [
        "Agora teste o modelo. Pegue um batch de de 10 exemplos do conjunto de treinamento e chame model.predict nestes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azBhDymo5U_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_batch = normed_train_data[:10]\n",
        "example_result = model.predict(example_batch)\n",
        "example_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oEw4bZgGCaXB"
      },
      "source": [
        "## Treinando o Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBBvhDQo5U_U",
        "colab_type": "text"
      },
      "source": [
        "Treine o modelo com 1000 epochs, e grave a acurácia do treinamento e da validação em um objeto history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VflXLEeECaXC",
        "colab": {}
      },
      "source": [
        "EPOCHS = 1000\n",
        "\n",
        "logdir = \"logs/\"\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "history = model.fit(\n",
        "  normed_train_data, train_labels,\n",
        "  epochs=EPOCHS, validation_split = 0.2,\n",
        " callbacks=[tensorboard_callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5hZi5Hb5U_X",
        "colab_type": "text"
      },
      "source": [
        "### TensorBoard - Execute no Terminal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhKj_Q_d5U_Z",
        "colab_type": "text"
      },
      "source": [
        "tensorboard --logdir=logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXW6D-l05U_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yWfgsmVXCaXG"
      },
      "source": [
        "Visualize o progresso do modelo de treinamento usando o estados armazenados no objeto history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3OM7raE5U_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzFGyP4d5U_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history(history):\n",
        "    hist = pd.DataFrame(history.history)\n",
        "    hist['epoch'] = history.epoch\n",
        "\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Mean Abs Error [MPG]')\n",
        "    plt.plot(hist['epoch'], hist['mean_absolute_error'],\n",
        "           label='Train Error')\n",
        "    plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n",
        "           label = 'Val Error')\n",
        "    plt.ylim([0,5])\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Mean Square Error [$MPG^2$]')\n",
        "    plt.plot(hist['epoch'], hist['mean_squared_error'],\n",
        "           label='Train Error')\n",
        "    plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n",
        "           label = 'Val Error')\n",
        "    plt.ylim([0,20])\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xsoS7CPDCaXH"
      },
      "source": [
        "Este grafo mostra as pequenas melhoras, ou mesmo a diminuição do validation error após 100 epochs. Vamos atualizar o model.fit para que pare automatixamente o treinamento quando o validation score não aumentar mais. Usaremos o EarlyStopping callback que testa a condição do treinamento a cada epoch. Se um grupo de epochs decorre sem mostrar melhoras, o treinamento irá parar automaticamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gl91RPhdCaXI",
        "colab": {}
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "# The patience parameter is the amount of epochs to check for improvement\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "history = model.fit(normed_train_data, train_labels, epochs=EPOCHS,\n",
        "                    validation_split = 0.2, verbose=0, callbacks=[early_stop])\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x9Kk1voUCaXJ"
      },
      "source": [
        "O gráfico mostra que no conjunto de validação, a média de erro é próximo de +/- 2MPG."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxroq7sA5U_l",
        "colab_type": "text"
      },
      "source": [
        "Vamos ver quão bem o modelo generaliza usando o conjunto de <b>teste</b>, que não usamos para treinar o modelo. Isso diz quão bem podemos esperar que o modelo se saia quando usarmos na vida real."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3DmJEUinCaXK",
        "colab": {}
      },
      "source": [
        "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=0)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS6LcZVD5U_o",
        "colab_type": "text"
      },
      "source": [
        "### Realizando Inferência"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etPpt-Dt5U_p",
        "colab_type": "text"
      },
      "source": [
        "Finalmente, prevejamos os valores MPG usando o conjunto de teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKSguExe5U_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions = model.predict(normed_test_data).flatten()\n",
        "\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values [MPG]')\n",
        "plt.ylabel('Predictions [MPG]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "_ = plt.plot([-100, 100], [-100, 100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7HKtspK5U_s",
        "colab_type": "text"
      },
      "source": [
        "Parece que o nosso modelo prediz razoavelmente bem. Vamos dar uma olhada na distribuição dos erros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7F-xATz5U_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "error = test_predictions - test_labels\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error [MPG]\")\n",
        "_ = plt.ylabel(\"Count\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni2LIs4T5U_v",
        "colab_type": "text"
      },
      "source": [
        "Embora não seja uma gaussiana perfeita, o distribuição dos erros possuem um comportamente bem próximo da normalidade, conforme análise gráfica."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKWH0buL5U_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}